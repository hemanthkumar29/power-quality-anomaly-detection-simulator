{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74403b52",
   "metadata": {},
   "source": [
    "# Power Quality Anomaly Detection - Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the PQ Anomaly Detection system.\n",
    "\n",
    "## Topics Covered:\n",
    "1. Data Generation and Loading\n",
    "2. Feature Extraction\n",
    "3. Model Training\n",
    "4. Evaluation and Visualization\n",
    "5. Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "from src.data_loader import PQDataLoader\n",
    "from src.feature_extraction import FeatureExtractor\n",
    "from src.model_training import PQModelTrainer\n",
    "from src.visualization import PQVisualizer\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1624cfb5",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Dataset\n",
    "\n",
    "We'll generate a small dataset with 5 classes of power quality anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "data_loader = PQDataLoader(data_dir='data')\n",
    "\n",
    "# Generate dataset (200 samples per class)\n",
    "waveforms, labels = data_loader.generate_synthetic_dataset(n_samples=200)\n",
    "\n",
    "print(f\"Dataset shape: {waveforms.shape}\")\n",
    "print(f\"Number of samples: {len(waveforms)}\")\n",
    "print(f\"Classes: {np.unique(labels)}\")\n",
    "print(f\"Samples per class: {len(labels) // len(np.unique(labels))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6476e1",
   "metadata": {},
   "source": [
    "## 2. Visualize Sample Waveforms\n",
    "\n",
    "Let's visualize one sample from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = PQVisualizer()\n",
    "\n",
    "# Get one sample from each class\n",
    "unique_classes = np.unique(labels)\n",
    "sample_waveforms = []\n",
    "sample_labels = []\n",
    "\n",
    "for class_name in unique_classes:\n",
    "    idx = np.where(labels == class_name)[0][0]\n",
    "    sample_waveforms.append(waveforms[idx])\n",
    "    sample_labels.append(class_name)\n",
    "\n",
    "# Plot multiple waveforms\n",
    "fig = visualizer.plot_multiple_waveforms(\n",
    "    sample_waveforms,\n",
    "    sample_labels,\n",
    "    title=\"Sample Waveforms by Class\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af755942",
   "metadata": {},
   "source": [
    "## 3. Detailed Waveform Analysis\n",
    "\n",
    "Analyze a single waveform in both time and frequency domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a harmonic waveform for analysis\n",
    "harmonic_idx = np.where(labels == 'Harmonic')[0][0]\n",
    "harmonic_waveform = waveforms[harmonic_idx]\n",
    "\n",
    "# Plot combined analysis\n",
    "fig = visualizer.plot_waveform_with_fft(\n",
    "    harmonic_waveform,\n",
    "    title=\"Harmonic Distortion Analysis\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24751097",
   "metadata": {},
   "source": [
    "## 4. Extract Features\n",
    "\n",
    "Extract time-domain and frequency-domain features from all waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c5b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature extractor\n",
    "feature_extractor = FeatureExtractor()\n",
    "\n",
    "# Extract features from all waveforms\n",
    "features = feature_extractor.extract_features_batch(waveforms)\n",
    "feature_names = feature_extractor.get_feature_names()\n",
    "\n",
    "print(f\"Features extracted: {features.shape[1]}\")\n",
    "print(f\"Feature names: {feature_names}\")\n",
    "\n",
    "# Create DataFrame for better visualization\n",
    "features_df = pd.DataFrame(features, columns=feature_names)\n",
    "features_df['label'] = labels\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nSample features:\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a120127",
   "metadata": {},
   "source": [
    "## 5. Feature Analysis by Class\n",
    "\n",
    "Analyze how features differ across anomaly types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary by class\n",
    "summary = features_df.groupby('label')[['rms_voltage', 'thd', 'dip_percentage', 'swell_percentage']].mean()\n",
    "print(\"Average feature values by class:\")\n",
    "print(summary)\n",
    "\n",
    "# Visualize\n",
    "summary.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Average Feature Values by Anomaly Type')\n",
    "plt.ylabel('Value')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062938f4",
   "metadata": {},
   "source": [
    "## 6. Train Machine Learning Models\n",
    "\n",
    "Train multiple ML models for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab53c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = PQModelTrainer(model_dir='models')\n",
    "\n",
    "# Prepare data (80-20 train-test split)\n",
    "X_train, X_test, y_train, y_test = trainer.prepare_data(features, labels, test_size=0.2)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289e823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = trainer.train_random_forest(X_train, y_train)\n",
    "print(\"✓ Random Forest trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d8859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "print(\"Training XGBoost...\")\n",
    "xgb_model = trainer.train_xgboost(X_train, y_train)\n",
    "print(\"✓ XGBoost trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad184d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_model = trainer.train_lightgbm(X_train, y_train)\n",
    "print(\"✓ LightGBM trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2492aa0",
   "metadata": {},
   "source": [
    "## 7. Evaluate Models\n",
    "\n",
    "Compare performance of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f96ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "results = trainer.evaluate_all_models(X_test, y_test)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [r['accuracy'] for r in results.values()],\n",
    "    'F1 (macro)': [r['f1_macro'] for r in results.values()],\n",
    "    'F1 (weighted)': [r['f1_weighted'] for r in results.values()]\n",
    "})\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "comparison.plot(x='Model', kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a26291",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix\n",
    "\n",
    "Visualize prediction errors for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c57c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get best model (highest accuracy)\n",
    "best_model_name = max(results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
    "best_result = results[best_model_name]\n",
    "\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "fig = visualizer.plot_confusion_matrix(\n",
    "    best_result['confusion_matrix'],\n",
    "    trainer.class_names,\n",
    "    title=f\"Confusion Matrix - {best_model_name.upper()}\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9a0464",
   "metadata": {},
   "source": [
    "## 9. Feature Importance\n",
    "\n",
    "Identify which features are most important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33b11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance for tree-based model\n",
    "importance = trainer.get_feature_importance('random_forest')\n",
    "\n",
    "if importance is not None:\n",
    "    # Plot feature importance\n",
    "    fig = visualizer.plot_feature_importance(\n",
    "        feature_names,\n",
    "        importance,\n",
    "        title=\"Feature Importance - Random Forest\",\n",
    "        top_n=15\n",
    "    )\n",
    "    plt.show()\n",
    "    \n",
    "    # Print top features\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    for i in range(10):\n",
    "        print(f\"{i+1}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca86f7",
   "metadata": {},
   "source": [
    "## 10. Make Predictions on New Data\n",
    "\n",
    "Use trained model to classify new waveforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7c9ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new test waveform\n",
    "time = np.linspace(0, 0.2, 1280)\n",
    "test_waveform = data_loader._generate_sag(time, 60)\n",
    "\n",
    "# Extract features\n",
    "test_features_dict = feature_extractor.extract_all_features(test_waveform)\n",
    "test_features = np.array([list(test_features_dict.values())])\n",
    "\n",
    "# Predict\n",
    "predictions, probabilities = trainer.predict(test_features, model_name='xgboost')\n",
    "\n",
    "print(f\"\\nPredicted class: {predictions[0]}\")\n",
    "print(\"\\nClass probabilities:\")\n",
    "for class_name, prob in zip(trainer.class_names, probabilities[0]):\n",
    "    print(f\"  {class_name}: {prob:.4f} ({prob*100:.2f}%)\")\n",
    "\n",
    "# Visualize the test waveform\n",
    "fig = visualizer.plot_waveform(\n",
    "    test_waveform,\n",
    "    title=f\"Test Waveform - Predicted: {predictions[0]}\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ae458",
   "metadata": {},
   "source": [
    "## 11. Save Models\n",
    "\n",
    "Save trained models for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed56b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models\n",
    "trainer.save_models()\n",
    "print(\"✓ Models saved to 'models/' directory\")\n",
    "\n",
    "# Save dataset\n",
    "data_loader.save_dataset(waveforms, labels)\n",
    "print(\"✓ Dataset saved to 'data/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ac74d",
   "metadata": {},
   "source": [
    "## 12. Load Saved Models\n",
    "\n",
    "Demonstrate loading previously saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5123a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new trainer instance\n",
    "new_trainer = PQModelTrainer(model_dir='models')\n",
    "\n",
    "# Load saved models\n",
    "new_trainer.load_models()\n",
    "print(f\"✓ Loaded {len(new_trainer.models)} models\")\n",
    "print(f\"Available models: {list(new_trainer.models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb3a14",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, we:\n",
    "1. Generated synthetic power quality waveforms\n",
    "2. Visualized different types of anomalies\n",
    "3. Extracted signal processing features\n",
    "4. Trained multiple ML models\n",
    "5. Evaluated and compared model performance\n",
    "6. Made predictions on new data\n",
    "7. Saved models for future use\n",
    "\n",
    "### Next Steps:\n",
    "- Try the web application: `streamlit run app.py`\n",
    "- Train on larger datasets for better accuracy\n",
    "- Experiment with custom features\n",
    "- Integrate with real power quality monitoring hardware"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
